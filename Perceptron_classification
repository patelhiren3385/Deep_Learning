'''Binary Classification Problem Solved using :: Perceptron'''
import pandas as pd
import sklearn.datasets
import numpy as np
from mpl_toolkits import mplot3d
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import binarize
from sklearn.metrics import accuracy_score

##############################################################################################
'''Loading DATA'''
##############################################################################################

cancer_data = sklearn.datasets.load_breast_cancer() #Binary Classification Problem DATA
x = cancer_data.data # .data will give FEATURES
y = cancer_data.target # .target will give LABELS

##############################################################################################
'''Data Processing'''
##############################################################################################

#pd.set_option('display.max_columns',None) #Viewing Options All the Columns
data = pd.DataFrame(cancer_data.data,columns=cancer_data.feature_names)
data['Labels'] = cancer_data.target #To add Lables columns to VIWEING DATA
xx = data.drop('Labels',axis=1) #This is Extraction of DATA in DATAFRAME TYPE
yy = data['Labels'] #This is Extraction of DATA in DATAFRAME TYPE
x_train,x_test,y_train,y_test = train_test_split(xx,yy,test_size=0.1,stratify=yy,random_state=1) #Stratify w.r.t. yy means we want to split the data in such a way that ratio of 0 and 1 reamain almost same in both test and train data: And Random state with int constant will make sure the data is split in same way each time we run the code means data is having same mean and other stat.

##############################################################################################
'''Perceptron with Classes'''
##############################################################################################

class Perceptron:
    def __init__(self):
        self.b = None
        self.w = None

    def sum(self,x_1):
        return 1 if (np.dot(self.w, x_1) >= self.b) else 0

    def prediction(self,x_0):
        y_pred = []
        for i in x_0:
            y_ = self.sum(i)
            y_pred.append(y_)
        return y_pred

    def learning_algo(self,x_2,y_2,epochs = 1,learning_rate = 1):
        self.w = np.ones(x_2.shape[1])
        self.b = 0
        acu = {}
        accu = 0
        for k in range(epochs):
            for i, j in zip(x_2, y_2):
                y_pred = self.sum(i)
                if j == 1 and y_pred == 0:
                    self.w = self.w + learning_rate*i
                    self.b = self.b + learning_rate*1
                elif j == 0 and y_pred == 1:
                    self.w = self.w - learning_rate*i
                    self.b = self.b - learning_rate*1
            acu[k] = accuracy_score(self.prediction(x_2),y_2)
            if acu[k] > accu:
                accu = acu[k]
                check_pointw = self.w
                check_pointb = self.b
        self.w = check_pointw
        self.b = check_pointb
        key_max = max(acu,key = acu.get)
        print('Optimum Value of b is:',self.b,'\nOptimum Value of w is:',self.w,'\nMaximum Accuracy is:',acu[key_max])

percep = Perceptron()
percep.learning_algo(x_train.values,y_train,100,0.0001)
y_pred_train = percep.prediction(x_train.values)
print('Train Accuracy with Optimum b and w values:',accuracy_score(y_pred_train,y_train))
